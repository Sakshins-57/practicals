#import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings 
#We do not want to see warnings
warnings.filterwarnings("ignore") 
#import data
data = pd.read_csv("uber.csv")
#Create a data copy
df = data.copy()
#Print data
df.head()

#Get Info
df.info()

#pickup_datetime is not in required data format
df["pickup_datetime"] = pd.to_datetime(df["pickup_datetime"])

df.info()

#Statistics of data
df.describe()

#Number of missing values
df.isnull().sum()

#Correlation
df.select_dtypes(include=[np.number]).corr()

print(df.columns)

#Drop the rows with missing values
df.dropna(inplace=True)

plt.boxplot(df['fare_amount'])
{'whiskers': [<matplotlib.lines.Line2D at 0x2174a300cd0>,
  <matplotlib.lines.Line2D at 0x2174a300e10>],
 'caps': [<matplotlib.lines.Line2D at 0x2174a300f50>,
  <matplotlib.lines.Line2D at 0x2174a301090>],
 'boxes': [<matplotlib.lines.Line2D at 0x2174a2f0b90>],
 'medians': [<matplotlib.lines.Line2D at 0x2174a3011d0>],
 'fliers': [<matplotlib.lines.Line2D at 0x2174a301310>],
 'means': []}

#Remove Outliers
q_low = df["fare_amount"].quantile(0.01)
q_hi  = df["fare_amount"].quantile(0.99)
df = df[(df["fare_amount"] < q_hi) & (df["fare_amount"] > q_low)]

#Check the missing values now
df.isnull().sum()

#Time to apply learning models
from sklearn.model_selection import train_test_split

#Take x as predictor variable
x = df.drop("fare_amount", axis = 1)
#And y as target variable
y = df['fare_amount']

#Necessary to apply model
x['pickup_datetime'] = pd.to_numeric(pd.to_datetime(x['pickup_datetime']))
x = x.loc[:, x.columns.str.contains('^Unnamed')]
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)

from sklearn.linear_model import LinearRegression

lrmodel = LinearRegression()
lrmodel.fit(x_train, y_train)

LinearRegression
?i
LinearRegression()

#Prediction
predict = lrmodel.predict(x_test)

#Visualization — Actual vs Predicted Fares
plt.figure(figsize=(12, 5))

# Linear Regression Plot
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_lr, color='blue', alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title(f'Linear Regression\nRMSE={lr_rmse:.2f}, R²={lr_r2:.2f}')
plt.xlabel('Actual Fare Amount')
plt.ylabel('Predicted Fare Amount')

# evaluation
from sklearn.metrics import mean_squared_error, r2_score

lr_rmse = np.sqrt(mean_squared_error(y_test, predict))
lr_r2 = r2_score(y_test, predict)

print("Linear Regression → RMSE:", lr_rmse, "R²:", lr_r2)
Linear Regression → RMSE: 8.063863046328835 R²: -2.6395537326528995e-05

#Let's Apply Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor
rfrmodel = RandomForestRegressor(n_estimators = 100, random_state = 101)

#Fit the Forest
rfrmodel.fit(x_train, y_train)
rfrmodel_pred = rfrmodel.predict(x_test)

rfr_rmse = np.sqrt(mean_squared_error(y_test, rfrmodel_pred))
rfr_r2 = r2_score(y_test, rfrmodel_pred)

print("Random Forest → RMSE:", rfr_rmse, "R²:", rfr_r2)
Random Forest → RMSE: 9.757713738069647 R²: -0.4642705335969681

# Random Forest Plot
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_rf, color='green', alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.title(f'Random Forest Regression\nRMSE={rf_rmse:.2f}, R²={rf_r2:.2f}')
plt.xlabel('Actual Fare Amount')
plt.ylabel('Predicted Fare Amount')

plt.tight_layout()
plt.show()

